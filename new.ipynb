{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c6f4922",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-29 21:50:41.765353: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from os import listdir\n",
    "import tensorflow as tf\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "#%matplotlib inline\n",
    "import imutils\n",
    "import shutil\n",
    "import pickle\n",
    "\n",
    "from keras.utils import image_dataset_from_directory\n",
    "from keras.models import Model,load_model\n",
    "from keras.layers import Conv2D,Input,ZeroPadding2D,BatchNormalization,Flatten,Activation,Dense,MaxPooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7cd50356",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dir = \"archive-2/Training\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b2fbc935",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_brain_contour(image, plot=False):\n",
    "    # Convert the image to grayscale, and blur it slightly\n",
    "    gray = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
    "    gray = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "\n",
    "    thresh = cv2.threshold(gray, 45, 255, cv2.THRESH_BINARY)[1]\n",
    "    thresh = cv2.erode(thresh, None, iterations=2)\n",
    "    thresh = cv2.dilate(thresh, None, iterations=2)\n",
    "\n",
    "    # Find contours in thresholded image, then grab the largest one\n",
    "    cnts = cv2.findContours(thresh.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    cnts = imutils.grab_contours(cnts)\n",
    "    c = max(cnts, key=cv2.contourArea)\n",
    "    # extreme points\n",
    "    extLeft = tuple(c[c[:, :, 0].argmin()][0])\n",
    "    extRight = tuple(c[c[:, :, 0].argmax()][0])\n",
    "    extTop = tuple(c[c[:, :, 1].argmin()][0])\n",
    "    extBot = tuple(c[c[:, :, 1].argmax()][0])\n",
    "\n",
    "    # crop new image out of the original image using the four extreme points (left, right, top, bottom)\n",
    "    new_image = image[extTop[1]:extBot[1], extLeft[0]:extRight[0]]\n",
    "\n",
    "    if plot:\n",
    "        plt.figure()\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.imshow(image)\n",
    "        plt.tick_params(axis='both', which='both', top=False, bottom=False, left=False, right=False, labelbottom=False,\n",
    "                        labeltop=False, labelleft=False, labelright=False)\n",
    "        plt.title('Original Image')\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.imshow(new_image)\n",
    "        plt.tick_params(axis='both', which='both', top=False, bottom=False, left=False, right=False, labelbottom=False,\n",
    "                        labeltop=False, labelleft=False, labelright=False)\n",
    "        plt.title('Cropped Image')\n",
    "        plt.show()\n",
    "\n",
    "    return new_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cda5957f",
   "metadata": {},
   "outputs": [],
   "source": [
    "destination_path = \"new_trainingdata\"\n",
    "if not os.path.exists(destination_path):\n",
    "    os.makedirs(destination_path)\n",
    "for type_folder in os.listdir(image_dir):\n",
    "    folder_path= os.path.join(image_dir,type_folder)\n",
    "    # print(folder_path)\n",
    "    destination_folder=os.path.join(destination_path,type_folder)\n",
    "    if not os.path.exists(destination_folder):\n",
    "        os.makedirs(destination_folder)\n",
    "    #if type_folder != \".DS_Store\":\n",
    "    for img_name in os.listdir(folder_path):\n",
    "        if type_folder == \".DS_Store\":\n",
    "            os.rmdir(type_folder)\n",
    "        else:\n",
    "            ex_img = cv2.imread(os.path.join(folder_path,img_name))\n",
    "            ex_crop_img = crop_brain_contour(ex_img, False)\n",
    "            cv2.imwrite(os.path.join(destination_folder,img_name),ex_crop_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "83d35844",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5712 files belonging to 4 classes.\n",
      "Using 4570 files for training.\n",
      "Using 1142 files for validation.\n"
     ]
    }
   ],
   "source": [
    "train_dt, val_dt = image_dataset_from_directory(\n",
    "    directory = destination_path,\n",
    "    labels=\"inferred\",\n",
    "    batch_size = 32,\n",
    "    image_size = (224, 224),\n",
    "    subset = \"both\",\n",
    "    validation_split = 0.2,\n",
    "    seed = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "056d75dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['glioma', 'meningioma', 'notumor', 'pituitary']\n"
     ]
    }
   ],
   "source": [
    "class_names = train_dt.class_names\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eab12720",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "train_dt = train_dt.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "val_dt = val_dt.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "291f2a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(input_shape):\n",
    "    X_input = Input(input_shape)\n",
    "    X = ZeroPadding2D((2, 2))(X_input)\n",
    "\n",
    "    X = Conv2D(32, (7, 7), strides=(1, 1))(X)\n",
    "    X = BatchNormalization(axis=3, name='bn0')(X)\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    X = MaxPooling2D((4, 4))(X)\n",
    "    X = MaxPooling2D((4, 4))(X)\n",
    "    X = Flatten()(X)\n",
    "    X = Dense(1, activation='sigmoid')(X)\n",
    "    model = Model(inputs=X_input, outputs=X)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d4675fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SHAPE = (224, 224, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1c451091",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2839f083",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "143/143 - 928s - loss: 15.2031 - accuracy: 0.2562 - val_loss: 1.3838 - val_accuracy: 0.2933 - 928s/epoch - 6s/step\n",
      "Epoch 2/100\n",
      "143/143 - 885s - loss: 1.3834 - accuracy: 0.2676 - val_loss: 1.3761 - val_accuracy: 0.3047 - 885s/epoch - 6s/step\n",
      "Epoch 3/100\n",
      "143/143 - 823s - loss: 1.3905 - accuracy: 0.2650 - val_loss: 1.3665 - val_accuracy: 0.3047 - 823s/epoch - 6s/step\n",
      "Epoch 4/100\n",
      "143/143 - 836s - loss: 1.3500 - accuracy: 0.2972 - val_loss: 1.2746 - val_accuracy: 0.3809 - 836s/epoch - 6s/step\n",
      "Epoch 5/100\n",
      "143/143 - 1087s - loss: 1.3048 - accuracy: 0.3536 - val_loss: 1.2841 - val_accuracy: 0.3774 - 1087s/epoch - 8s/step\n",
      "Epoch 6/100\n",
      "143/143 - 1166s - loss: 1.2940 - accuracy: 0.3626 - val_loss: 1.2506 - val_accuracy: 0.4011 - 1166s/epoch - 8s/step\n",
      "Epoch 7/100\n",
      "143/143 - 1174s - loss: 1.2879 - accuracy: 0.3527 - val_loss: 1.2445 - val_accuracy: 0.4011 - 1174s/epoch - 8s/step\n",
      "Epoch 8/100\n",
      "143/143 - 958s - loss: 1.2700 - accuracy: 0.3746 - val_loss: 1.2264 - val_accuracy: 0.4203 - 958s/epoch - 7s/step\n",
      "Epoch 9/100\n",
      "143/143 - 822s - loss: 1.2574 - accuracy: 0.3775 - val_loss: 1.2256 - val_accuracy: 0.4203 - 822s/epoch - 6s/step\n",
      "Epoch 10/100\n",
      "143/143 - 805s - loss: 1.2459 - accuracy: 0.3845 - val_loss: 1.2218 - val_accuracy: 0.4212 - 805s/epoch - 6s/step\n",
      "Epoch 11/100\n",
      "143/143 - 817s - loss: 1.2734 - accuracy: 0.3869 - val_loss: 1.2326 - val_accuracy: 0.4247 - 817s/epoch - 6s/step\n",
      "Epoch 12/100\n",
      "143/143 - 816s - loss: 1.2511 - accuracy: 0.3851 - val_loss: 1.2246 - val_accuracy: 0.4247 - 816s/epoch - 6s/step\n",
      "Epoch 13/100\n",
      "143/143 - 954s - loss: 1.2469 - accuracy: 0.3993 - val_loss: 1.2839 - val_accuracy: 0.4089 - 954s/epoch - 7s/step\n",
      "Epoch 14/100\n",
      "143/143 - 938s - loss: 1.2240 - accuracy: 0.4042 - val_loss: 1.2537 - val_accuracy: 0.4431 - 938s/epoch - 7s/step\n",
      "Epoch 15/100\n",
      "143/143 - 1013s - loss: 1.2013 - accuracy: 0.4131 - val_loss: 1.2063 - val_accuracy: 0.4396 - 1013s/epoch - 7s/step\n",
      "Epoch 16/100\n",
      "143/143 - 987s - loss: 1.1910 - accuracy: 0.4208 - val_loss: 1.1764 - val_accuracy: 0.4440 - 987s/epoch - 7s/step\n",
      "Epoch 17/100\n",
      "143/143 - 1012s - loss: 1.1751 - accuracy: 0.4326 - val_loss: 1.1839 - val_accuracy: 0.4387 - 1012s/epoch - 7s/step\n",
      "Epoch 18/100\n",
      "143/143 - 1333s - loss: 1.1702 - accuracy: 0.4352 - val_loss: 1.1709 - val_accuracy: 0.4475 - 1333s/epoch - 9s/step\n",
      "Epoch 19/100\n",
      "143/143 - 3505s - loss: 1.1468 - accuracy: 0.4464 - val_loss: 1.1922 - val_accuracy: 0.4492 - 3505s/epoch - 25s/step\n",
      "Epoch 20/100\n",
      "143/143 - 4450s - loss: 1.1451 - accuracy: 0.4425 - val_loss: 1.1878 - val_accuracy: 0.4720 - 4450s/epoch - 31s/step\n",
      "Epoch 21/100\n",
      "143/143 - 1096s - loss: 1.1338 - accuracy: 0.4532 - val_loss: 1.1716 - val_accuracy: 0.4930 - 1096s/epoch - 8s/step\n",
      "Epoch 22/100\n",
      "143/143 - 956s - loss: 1.1203 - accuracy: 0.4600 - val_loss: 1.1991 - val_accuracy: 0.4694 - 956s/epoch - 7s/step\n",
      "Epoch 23/100\n",
      "143/143 - 1007s - loss: 1.1055 - accuracy: 0.4681 - val_loss: 1.1634 - val_accuracy: 0.4895 - 1007s/epoch - 7s/step\n",
      "Epoch 24/100\n",
      "143/143 - 1509s - loss: 1.1114 - accuracy: 0.4731 - val_loss: 1.1891 - val_accuracy: 0.4860 - 1509s/epoch - 11s/step\n",
      "Epoch 25/100\n",
      "143/143 - 979s - loss: 1.0821 - accuracy: 0.4895 - val_loss: 1.1629 - val_accuracy: 0.5201 - 979s/epoch - 7s/step\n",
      "Epoch 26/100\n",
      "143/143 - 856s - loss: 1.0687 - accuracy: 0.4976 - val_loss: 1.1686 - val_accuracy: 0.5018 - 856s/epoch - 6s/step\n",
      "Epoch 27/100\n",
      "143/143 - 1259s - loss: 1.0477 - accuracy: 0.5007 - val_loss: 1.1482 - val_accuracy: 0.5105 - 1259s/epoch - 9s/step\n",
      "Epoch 28/100\n",
      "143/143 - 880s - loss: 1.0321 - accuracy: 0.5105 - val_loss: 1.1979 - val_accuracy: 0.4895 - 880s/epoch - 6s/step\n",
      "Epoch 29/100\n",
      "143/143 - 901s - loss: 1.1130 - accuracy: 0.4707 - val_loss: 1.1739 - val_accuracy: 0.4729 - 901s/epoch - 6s/step\n",
      "Epoch 30/100\n",
      "143/143 - 807s - loss: 1.0412 - accuracy: 0.5120 - val_loss: 1.1334 - val_accuracy: 0.5026 - 807s/epoch - 6s/step\n",
      "Epoch 31/100\n",
      "143/143 - 1243s - loss: 1.0264 - accuracy: 0.5276 - val_loss: 1.1270 - val_accuracy: 0.5053 - 1243s/epoch - 9s/step\n",
      "Epoch 32/100\n",
      "143/143 - 3805s - loss: 0.9833 - accuracy: 0.5486 - val_loss: 1.1556 - val_accuracy: 0.5342 - 3805s/epoch - 27s/step\n",
      "Epoch 33/100\n",
      "143/143 - 768s - loss: 0.9613 - accuracy: 0.5908 - val_loss: 1.0941 - val_accuracy: 0.5718 - 768s/epoch - 5s/step\n",
      "Epoch 34/100\n",
      "143/143 - 773s - loss: 0.9165 - accuracy: 0.6171 - val_loss: 1.0453 - val_accuracy: 0.5884 - 773s/epoch - 5s/step\n",
      "Epoch 35/100\n",
      "143/143 - 762s - loss: 0.8946 - accuracy: 0.6352 - val_loss: 1.1013 - val_accuracy: 0.5911 - 762s/epoch - 5s/step\n",
      "Epoch 36/100\n",
      "143/143 - 2409s - loss: 0.8343 - accuracy: 0.6667 - val_loss: 1.0770 - val_accuracy: 0.6138 - 2409s/epoch - 17s/step\n",
      "Epoch 37/100\n",
      "143/143 - 11106s - loss: 0.7724 - accuracy: 0.7009 - val_loss: 1.0622 - val_accuracy: 0.6182 - 11106s/epoch - 78s/step\n",
      "Epoch 38/100\n",
      "143/143 - 20522s - loss: 0.7192 - accuracy: 0.7201 - val_loss: 1.0445 - val_accuracy: 0.6156 - 20522s/epoch - 144s/step\n",
      "Epoch 39/100\n",
      "143/143 - 4327s - loss: 0.6407 - accuracy: 0.7455 - val_loss: 1.0615 - val_accuracy: 0.6165 - 4327s/epoch - 30s/step\n",
      "Epoch 40/100\n",
      "143/143 - 1282s - loss: 0.6033 - accuracy: 0.7611 - val_loss: 1.0277 - val_accuracy: 0.6349 - 1282s/epoch - 9s/step\n",
      "Epoch 41/100\n",
      "143/143 - 1186s - loss: 0.5595 - accuracy: 0.7755 - val_loss: 1.0447 - val_accuracy: 0.6462 - 1186s/epoch - 8s/step\n",
      "Epoch 42/100\n",
      "143/143 - 4580s - loss: 0.4882 - accuracy: 0.8015 - val_loss: 1.0710 - val_accuracy: 0.6926 - 4580s/epoch - 32s/step\n",
      "Epoch 43/100\n",
      "143/143 - 4506s - loss: 0.4828 - accuracy: 0.8201 - val_loss: 1.0078 - val_accuracy: 0.7102 - 4506s/epoch - 32s/step\n",
      "Epoch 44/100\n",
      "143/143 - 2017s - loss: 0.4196 - accuracy: 0.8473 - val_loss: 1.0534 - val_accuracy: 0.6961 - 2017s/epoch - 14s/step\n",
      "Epoch 45/100\n",
      "143/143 - 1343s - loss: 0.3633 - accuracy: 0.8716 - val_loss: 1.2124 - val_accuracy: 0.7014 - 1343s/epoch - 9s/step\n",
      "Epoch 46/100\n",
      "143/143 - 3130s - loss: 0.3887 - accuracy: 0.8744 - val_loss: 1.0688 - val_accuracy: 0.7049 - 3130s/epoch - 22s/step\n",
      "Epoch 47/100\n",
      "143/143 - 2052s - loss: 0.3483 - accuracy: 0.8814 - val_loss: 1.0996 - val_accuracy: 0.7145 - 2052s/epoch - 14s/step\n",
      "Epoch 48/100\n",
      "143/143 - 1588s - loss: 0.3003 - accuracy: 0.9094 - val_loss: 1.2619 - val_accuracy: 0.7356 - 1588s/epoch - 11s/step\n",
      "Epoch 49/100\n",
      "143/143 - 1137s - loss: 0.2578 - accuracy: 0.9204 - val_loss: 1.5312 - val_accuracy: 0.7110 - 1137s/epoch - 8s/step\n",
      "Epoch 50/100\n",
      "143/143 - 3326s - loss: 0.2879 - accuracy: 0.9120 - val_loss: 1.0821 - val_accuracy: 0.7338 - 3326s/epoch - 23s/step\n",
      "Epoch 51/100\n",
      "143/143 - 974s - loss: 0.2233 - accuracy: 0.9346 - val_loss: 1.1465 - val_accuracy: 0.7399 - 974s/epoch - 7s/step\n",
      "Epoch 52/100\n",
      "143/143 - 1540s - loss: 0.1916 - accuracy: 0.9457 - val_loss: 1.3663 - val_accuracy: 0.7382 - 1540s/epoch - 11s/step\n",
      "Epoch 53/100\n",
      "143/143 - 1160s - loss: 0.2852 - accuracy: 0.9057 - val_loss: 1.3724 - val_accuracy: 0.7207 - 1160s/epoch - 8s/step\n",
      "Epoch 54/100\n",
      "143/143 - 3930s - loss: 0.2098 - accuracy: 0.9389 - val_loss: 1.3326 - val_accuracy: 0.7636 - 3930s/epoch - 27s/step\n",
      "Epoch 55/100\n",
      "143/143 - 6798s - loss: 0.1665 - accuracy: 0.9484 - val_loss: 1.2032 - val_accuracy: 0.7662 - 6798s/epoch - 48s/step\n",
      "Epoch 56/100\n",
      "143/143 - 4412s - loss: 0.1577 - accuracy: 0.9560 - val_loss: 1.3909 - val_accuracy: 0.7469 - 4412s/epoch - 31s/step\n",
      "Epoch 57/100\n",
      "143/143 - 37141s - loss: 0.1676 - accuracy: 0.9573 - val_loss: 1.3851 - val_accuracy: 0.7539 - 37141s/epoch - 260s/step\n",
      "Epoch 58/100\n",
      "143/143 - 3549s - loss: 0.1308 - accuracy: 0.9648 - val_loss: 1.4437 - val_accuracy: 0.7496 - 3549s/epoch - 25s/step\n",
      "Epoch 59/100\n",
      "143/143 - 1007s - loss: 0.1477 - accuracy: 0.9652 - val_loss: 1.3044 - val_accuracy: 0.7627 - 1007s/epoch - 7s/step\n",
      "Epoch 60/100\n",
      "143/143 - 1033s - loss: 0.1356 - accuracy: 0.9659 - val_loss: 2.1748 - val_accuracy: 0.6926 - 1033s/epoch - 7s/step\n",
      "Epoch 61/100\n",
      "143/143 - 1039s - loss: 0.1448 - accuracy: 0.9639 - val_loss: 1.3678 - val_accuracy: 0.7680 - 1039s/epoch - 7s/step\n",
      "Epoch 62/100\n",
      "143/143 - 6767s - loss: 0.1458 - accuracy: 0.9593 - val_loss: 1.4807 - val_accuracy: 0.7513 - 6767s/epoch - 47s/step\n",
      "Epoch 63/100\n",
      "143/143 - 2897s - loss: 0.1329 - accuracy: 0.9641 - val_loss: 1.2943 - val_accuracy: 0.7601 - 2897s/epoch - 20s/step\n",
      "Epoch 64/100\n",
      "143/143 - 2039s - loss: 0.1232 - accuracy: 0.9681 - val_loss: 1.0754 - val_accuracy: 0.7732 - 2039s/epoch - 14s/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65/100\n",
      "143/143 - 1506s - loss: 0.0950 - accuracy: 0.9735 - val_loss: 1.3845 - val_accuracy: 0.7522 - 1506s/epoch - 11s/step\n",
      "Epoch 66/100\n",
      "143/143 - 1256s - loss: 0.1080 - accuracy: 0.9726 - val_loss: 1.4359 - val_accuracy: 0.7452 - 1256s/epoch - 9s/step\n",
      "Epoch 67/100\n",
      "143/143 - 15935s - loss: 0.1039 - accuracy: 0.9731 - val_loss: 1.2605 - val_accuracy: 0.7653 - 15935s/epoch - 111s/step\n",
      "Epoch 68/100\n",
      "143/143 - 2653s - loss: 0.0976 - accuracy: 0.9783 - val_loss: 1.4590 - val_accuracy: 0.7408 - 2653s/epoch - 19s/step\n",
      "Epoch 69/100\n",
      "143/143 - 1338s - loss: 0.0818 - accuracy: 0.9779 - val_loss: 1.4156 - val_accuracy: 0.7583 - 1338s/epoch - 9s/step\n",
      "Epoch 70/100\n",
      "143/143 - 1371s - loss: 0.1269 - accuracy: 0.9674 - val_loss: 1.4394 - val_accuracy: 0.7601 - 1371s/epoch - 10s/step\n",
      "Epoch 71/100\n",
      "143/143 - 5704s - loss: 0.0988 - accuracy: 0.9748 - val_loss: 1.2801 - val_accuracy: 0.7715 - 5704s/epoch - 40s/step\n",
      "Epoch 72/100\n",
      "143/143 - 2482s - loss: 0.0896 - accuracy: 0.9759 - val_loss: 1.4107 - val_accuracy: 0.7680 - 2482s/epoch - 17s/step\n",
      "Epoch 73/100\n",
      "143/143 - 1148s - loss: 0.0989 - accuracy: 0.9718 - val_loss: 1.7459 - val_accuracy: 0.7566 - 1148s/epoch - 8s/step\n",
      "Epoch 74/100\n",
      "143/143 - 36965s - loss: 0.0899 - accuracy: 0.9731 - val_loss: 1.7791 - val_accuracy: 0.7513 - 36965s/epoch - 258s/step\n",
      "Epoch 75/100\n",
      "143/143 - 3936s - loss: 0.1426 - accuracy: 0.9650 - val_loss: 1.5685 - val_accuracy: 0.7557 - 3936s/epoch - 28s/step\n",
      "Epoch 76/100\n",
      "143/143 - 980s - loss: 0.1122 - accuracy: 0.9698 - val_loss: 1.6875 - val_accuracy: 0.7583 - 980s/epoch - 7s/step\n",
      "Epoch 77/100\n",
      "143/143 - 902s - loss: 0.1412 - accuracy: 0.9672 - val_loss: 1.2480 - val_accuracy: 0.7338 - 902s/epoch - 6s/step\n",
      "Epoch 78/100\n",
      "143/143 - 882s - loss: 0.1091 - accuracy: 0.9718 - val_loss: 1.3475 - val_accuracy: 0.7627 - 882s/epoch - 6s/step\n",
      "Epoch 79/100\n",
      "143/143 - 956s - loss: 0.0702 - accuracy: 0.9801 - val_loss: 1.3283 - val_accuracy: 0.7662 - 956s/epoch - 7s/step\n",
      "Epoch 80/100\n",
      "143/143 - 1625s - loss: 0.0855 - accuracy: 0.9790 - val_loss: 1.6717 - val_accuracy: 0.7391 - 1625s/epoch - 11s/step\n",
      "Epoch 81/100\n",
      "143/143 - 1886s - loss: 0.1139 - accuracy: 0.9737 - val_loss: 1.5101 - val_accuracy: 0.7277 - 1886s/epoch - 13s/step\n",
      "Epoch 82/100\n",
      "143/143 - 1354s - loss: 0.1018 - accuracy: 0.9746 - val_loss: 1.5231 - val_accuracy: 0.7592 - 1354s/epoch - 9s/step\n",
      "Epoch 83/100\n",
      "143/143 - 1813s - loss: 0.0649 - accuracy: 0.9849 - val_loss: 1.7691 - val_accuracy: 0.7443 - 1813s/epoch - 13s/step\n",
      "Epoch 84/100\n",
      "143/143 - 871s - loss: 0.0512 - accuracy: 0.9862 - val_loss: 1.5331 - val_accuracy: 0.7609 - 871s/epoch - 6s/step\n",
      "Epoch 85/100\n",
      "143/143 - 887s - loss: 0.0515 - accuracy: 0.9880 - val_loss: 1.3918 - val_accuracy: 0.7566 - 887s/epoch - 6s/step\n",
      "Epoch 86/100\n",
      "143/143 - 896s - loss: 0.0376 - accuracy: 0.9882 - val_loss: 1.6335 - val_accuracy: 0.7644 - 896s/epoch - 6s/step\n",
      "Epoch 87/100\n",
      "143/143 - 902s - loss: 0.0285 - accuracy: 0.9917 - val_loss: 1.8080 - val_accuracy: 0.7732 - 902s/epoch - 6s/step\n",
      "Epoch 88/100\n",
      "143/143 - 929s - loss: 0.0621 - accuracy: 0.9853 - val_loss: 1.5692 - val_accuracy: 0.7662 - 929s/epoch - 6s/step\n",
      "Epoch 89/100\n",
      "143/143 - 746s - loss: 0.0820 - accuracy: 0.9801 - val_loss: 1.6046 - val_accuracy: 0.7548 - 746s/epoch - 5s/step\n",
      "Epoch 90/100\n",
      "143/143 - 2106s - loss: 0.0377 - accuracy: 0.9893 - val_loss: 1.3816 - val_accuracy: 0.7680 - 2106s/epoch - 15s/step\n",
      "Epoch 91/100\n",
      "143/143 - 988s - loss: 0.0484 - accuracy: 0.9867 - val_loss: 1.9129 - val_accuracy: 0.7618 - 988s/epoch - 7s/step\n",
      "Epoch 92/100\n",
      "143/143 - 869s - loss: 0.0468 - accuracy: 0.9864 - val_loss: 1.8028 - val_accuracy: 0.7329 - 869s/epoch - 6s/step\n",
      "Epoch 93/100\n",
      "143/143 - 14493s - loss: 0.0833 - accuracy: 0.9764 - val_loss: 1.5447 - val_accuracy: 0.7662 - 14493s/epoch - 101s/step\n",
      "Epoch 94/100\n",
      "143/143 - 1261s - loss: 0.0812 - accuracy: 0.9792 - val_loss: 1.8032 - val_accuracy: 0.7417 - 1261s/epoch - 9s/step\n",
      "Epoch 95/100\n",
      "143/143 - 3525s - loss: 0.0743 - accuracy: 0.9799 - val_loss: 1.4424 - val_accuracy: 0.7828 - 3525s/epoch - 25s/step\n",
      "Epoch 96/100\n",
      "143/143 - 956s - loss: 0.0348 - accuracy: 0.9910 - val_loss: 1.7887 - val_accuracy: 0.7776 - 956s/epoch - 7s/step\n",
      "Epoch 97/100\n",
      "143/143 - 1883s - loss: 0.0587 - accuracy: 0.9847 - val_loss: 1.5015 - val_accuracy: 0.7504 - 1883s/epoch - 13s/step\n",
      "Epoch 98/100\n",
      "143/143 - 1104s - loss: 0.0340 - accuracy: 0.9899 - val_loss: 1.4245 - val_accuracy: 0.7767 - 1104s/epoch - 8s/step\n",
      "Epoch 99/100\n",
      "143/143 - 886s - loss: 0.0315 - accuracy: 0.9912 - val_loss: 1.6306 - val_accuracy: 0.7715 - 886s/epoch - 6s/step\n",
      "Epoch 100/100\n",
      "143/143 - 821s - loss: 0.0336 - accuracy: 0.9897 - val_loss: 1.6628 - val_accuracy: 0.7644 - 821s/epoch - 6s/step\n"
     ]
    }
   ],
   "source": [
    "model_1 = tf.keras.Sequential(layers=[\n",
    "    tf.keras.layers.Conv2D(filters=64, kernel_size=2, activation=\"relu\"),\n",
    "    tf.keras.layers.Conv2D(filters=64, kernel_size=2, activation=\"relu\"),\n",
    "    tf.keras.layers.MaxPool2D(pool_size=2, strides=(1, 1)),\n",
    "\n",
    "    tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation=\"relu\"),\n",
    "    tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation=\"relu\"),\n",
    "    tf.keras.layers.MaxPool2D(pool_size=2, strides=(1, 1)),\n",
    "\n",
    "    tf.keras.layers.Conv2D(filters=16, kernel_size=3, activation=\"relu\"),\n",
    "    tf.keras.layers.Conv2D(filters=16, kernel_size=3, activation=\"relu\"),\n",
    "    tf.keras.layers.MaxPool2D(pool_size=2, strides=(1, 1)),\n",
    "\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128, activation=\"relu\"),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(64, activation=\"relu\"),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(32, activation=\"relu\"),\n",
    "\n",
    "    tf.keras.layers.Dense(4, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "model_1.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "                optimizer=tf.keras.optimizers.Adam(learning_rate=0.0014),\n",
    "                metrics=[\"accuracy\"])\n",
    "\n",
    "epochs = 100\n",
    "history_1 = model_1.fit(train_dt,\n",
    "                        validation_data=val_dt,\n",
    "                        epochs=epochs,\n",
    "                        steps_per_epoch=len(train_dt),\n",
    "                        validation_steps=len(val_dt),\n",
    "                        verbose=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c904c0df",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 6). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://db6b1d21-7942-4f5e-aabb-0057543b7417/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://db6b1d21-7942-4f5e-aabb-0057543b7417/assets\n"
     ]
    }
   ],
   "source": [
    "with open(\"model_1.pkl\", \"wb\") as file:\n",
    "    pickle.dump(history_1, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "28634e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('model_1.pkl','rb') as file:\n",
    "    pipeline = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "44ece31b",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Sequential' object has no attribute 'pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mmodel_1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpkl\u001b[49m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Sequential' object has no attribute 'pkl'"
     ]
    }
   ],
   "source": [
    "print(model_1.pkl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f17dd44d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'git'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mgit\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'git'"
     ]
    }
   ],
   "source": [
    "import git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc3ece0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
